---
title: "Linux内存管理"
date: 2025-03-15
layout: post
categories: 
- PWN,linux
tags: 
- PWN,linux
---

本篇文章详细介绍linux内核的内存管理，主要分为两部分，介绍伙伴算法和slab分配器-SLUB的工作机制，重点放在后面部分。

我们说的内存管理器是指 `page allocator` 与 `slab allocator` ：

page allocator: 负责管理整个系统的物理内存的分配，linux的page分配器基于伙伴系统buddy system

slab allocator: 负责堆内存分配，有很多种，我们主要谈论SLUB的实现。

我们可以通过 `cat /proc/buddyinfo` 与 `cat /proc/pagetypeinfo` 查看页面相关信息：

<!--more-->

## CPU的分页机制

一切的一切从CPU的分页机制谈起&#x2026;

由于物理内存管理使用页表结构会根据芯片架构的不同而有所不同，这里以x86-64架构为例来介绍：


### Virtual memory layout

[Kernel address space]<https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt>

cpu有一个CR3寄存器存放第一级页表（PGD）的物理地址。页表中的每一个表项(后面简称entry)必须要4KB大小对齐。
每一个page table entry 都是一个 `unsigned long(uint64_t)(declared as pxxval_t)` 类型的值，通过将这些类型中的每一个封装在一个结构体中，可以强制执行一些makeshift类型安全比如 `typedef struct { pgdval_t pgd; } pgd_t` 。PageTable的结构依赖于Intel 5-level paging是否开启，检查方式在[check\_la57\_support()](<https://elixir.bootlin.com/linux/v6.6/source/arch/x86/kernel/head64.c#L105>)。

虚拟地址空间是由 [\_\_VIRTUAL\_MASK](<https://elixir.bootlin.com/linux/v6.6/source/arch/x86/include/asm/page_types.h#L14>)和[\_\_VIRTUAL\_MASK\_SHIFT](<https://elixir.bootlin.com/linux/v6.6/source/arch/x86/include/asm/page_64_types.h#L57>)决定的。

`#define __VIRTUAL_MASK		((1UL << __VIRTUAL_MASK_SHIFT) - 1)`

`#define __VIRTUAL_MASK_SHIFT	(pgtable_l5_enabled() ? 56 : 47)`

| Level | Count | Shift | Description |
|---|---|---|---|
| PGD | [PTRS\_PER\_PGD][6] (512) | [PGDIR\_SHIFT][13] (48 or 39) | Page Global Directory |
| P4D | [PTRS\_PER\_P4D][7] (512 or 1) | [P4D\_SHIFT][14] (39) | Page 4 Directory() |
| PUD | [PTRS\_PER\_PUD][10] (512) | [PUD\_SHIFT][14] (30) | Page Upper Directory |
| PMD | [PTRS\_PER\_PMD][11] (512) | [PMD\_SHIFT][15] (21) | Page Middle Directory |
| PTE | [PTRS\_PER\_PTE][12] (512) | [PAGE\_SHIFT][16] (12) | Page Table Entry directory |

以下是分别在4级5级页表结构中虚拟地址的各个位在寻址时代表在各级目录表项的索引。

在 4 级页表的 x86-64 架构中，虚拟地址空间为 48 位。

```C


                                    48 bits
<--------------><---------------------------------------------->
   6         5         4         3         2         1
---|---------|---------|---------|---------|---------|----------
3210987654321098765432109876543210987654321098765432109876543210
                [  PGD  ][  PUD  ][  PMD  ][  PTE  ][  OFFSET  ]
111111111111111111111111111111111111111111100000000|000000000000  PMD_MASK
111111111111111111111111111111111100000000|00000000|000000000000  PUD_MASK
111111111111111111111111100000000|00000000|00000000|000000000000  PGDIR_MASK
                        |        |        |        |
                        |        |        |        |
                        |        |        |        |------------- PAGE_SHIFT  (12)
                        |        |        |---------------------- PMD_SHIFT   (21)
                        |        |------------------------------- PUD_SHIFT   (30)
                        |---------------------------------------- PGDIR_SHIFT (39)
```

`512 * 1 * 512 * 512 * 512 = 68.7bn 4KiB pages = 256 TiB` ，四级页表模式可以寻址空间在256TB

地址空间排布

```C
Userland (128 TiB)
                        0000000000000000 -> |---------------| ^
                                            |    Process    | |
                                            |    address    | | 128 TiB
                                            |     space     | |
                        0000800000000000 -> |---------------| v
                     .        ` .     -                 `-       ./   _
                              _    .`   -   The netherworld of  `/   `
                    -     `  _        |  /      unavailable sign-extended -/ .
                     ` -        .   `  48-bit address space  -     \  /    -
                   \-                - . . . .             \      /       -
Kernel (128 TiB)
                        ffff800000000000 -> |----------------| ^
                                            |   Hypervisor   | |
                                            |    reserved    | | 8 TiB
                                            |      space     | |
                        ffff880000000000 -> |----------------| x
                                            | LDT remap for  | | 0.5 TiB
                                            |       PTI      | |
[kaslr]   PAGE_OFFSET = ffff888000000000 -> |----------------| x
                                            | Direct mapping | |
                                            |  of all phys.  | | 64 TiB
                                            |     memory     | |
                        ffffc88000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
[kaslr] VMALLOC_START = ffffc90000000000 -> |----------------| ^
                                            |    vmalloc/    | |
                                            |    ioremap     | | 32 TiB
                                            |     space      | |
      VMALLOC_END + 1 = ffffe90000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
[kaslr] VMEMMAP_START = ffffea0000000000 -> |----------------| ^
                                            |     Virtual    | |
                                            |   memory map   | | 1 TiB
                                            |  (struct page  | |
                                            |     array)     | |
                        ffffeb0000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
                        ffffec0000000000 -> |----------------| ^
                                            |  KASAN shadow  | | 16 TiB
                                            |     memory     | |
                        fffffc0000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
                        fffffe0000000000 -> |----------------| ^
                                            | cpu_entry_area | | 0.5 TiB
                                            |     mapping    | |
                        fffffe8000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
     ESPFIX_BASE_ADDR = ffffff0000000000 -> |----------------| ^
                                            |   %esp fixup   | | 0.5 TiB
                                            |     stacks     | |
                        ffffff8000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
           EFI_VA_END = ffffffef00000000 -> |----------------| ^
                                            |   EFI region   | | 64 GiB
                                            | mapping space  | |
         EFI_VA_START = ffffffff00000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
   __START_KERNEL_map = ffffffff80000000 -> |----------------| ^
                                            |     Kernel     | |
                                            |      text      | | KERNEL_IMAGE_SIZE = 1 GiB *
                                            |     mapping    | |
        MODULES_VADDR = ffffffffc0000000 -> |----------------| x *
                                            |     Module     | |
                                            |    mapping     | | 1 GiB *
                                            |     space      | |
                        ffffffffff600000 -> |----------------| x
                                            |   vsyscalls    | | 8 MiB
                        ffffffffffe00000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
                                            ------------------


```

在 5 级页表的 x86-64 架构中，虚拟地址空间扩展到了 57 位。

```C


                               57 bits
<-----><------------------------------------------------------->
   6         5         4         3         2         1
---|---------|---------|---------|---------|---------|----------
3210987654321098765432109876543210987654321098765432109876543210
       [  PGD  ][  P4D  ][  PUD  ][  PMD  ][  PTE  ][  OFFSET  ]
111111111111111111111111111111111111111111100000000|000000000000  PMD_MASK
111111111111111111111111111111111100000000|00000000|000000000000  PUD_MASK
111111111111111111111111100000000|00000000|00000000|000000000000  P4D_MASK
111111111111111100000000|00000000|00000000|00000000|000000000000  PGDIR_MASK
               |        |        |        |        |
               |        |        |        |        |------------- PAGE_SHIFT  (12)
               |        |        |        |---------------------- PMD_SHIFT   (21)
               |        |        |------------------------------- PUD_SHIFT   (30)
               |        |---------------------------------------- P4D_SHIFT   (39)
               |------------------------------------------------- PGDIR_SHIFT (48)

```

``512 * 512 * 512 * 512 * 512` = 35.2tn 4KiB pages = 128 PiB`` ，五级页表模式可以寻址空间在128PB

```C
Userland (64 PiB)
                        0000000000000000 -> |---------------| ^
                                            |    Process    | |
                                            |    address    | | 64 PiB
                                            |     space     | |
                        0100000000000000 -> |---------------| v
                     .        ` .     -                 `-       ./   _
                              _    .`   -   The netherworld of  `/   `
                    -     `  _        |  /      unavailable sign-extended -/ .
                     ` -        .   `  57-bit address space  -     \  /    -
                   \-                - . . . .             \      /       -
Kernel (64 PiB)
                        ff00000000000000 -> |----------------| ^
                                            |   Hypervisor   | |
                                            |    reserved    | | 4 PiB
                                            |      space     | |
                        ff10000000000000 -> |----------------| x
                                            | LDT remap for  | | 0.25 PiB
                                            |       PTI      | |
[kaslr]   PAGE_OFFSET = ff11000000000000 -> |----------------| x
                                            | Direct mapping | |
                                            |  of all phys.  | | 32 PiB
                                            |     memory     | |
                        ff91000000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
[kaslr] VMALLOC_START = ffa0000000000000 -> |----------------| ^
                                            |    vmalloc/    | |
                                            |    ioremap     | | 12.5 PiB
                                            |     space      | |
      VMALLOC_END + 1 = ffd2000000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
[kaslr] VMEMMAP_START = ffd4000000000000 -> |----------------| ^
                                            |     Virtual    | |
                                            |   memory map   | | 0.5 PiB
                                            |  (struct page  | |
                                            |     array)     | |
                        ffd6000000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
                        ffdf000000000000 -> |----------------| ^
                                            |  KASAN shadow  | | 8 PiB
                                            |     memory     | |
                        fffffc0000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
                        fffffe0000000000 -> |----------------| ^
                                            | cpu_entry_area | | 0.5 TiB
                                            |     mapping    | |
                        fffffe8000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
     ESPFIX_BASE_ADDR = ffffff0000000000 -> |----------------| ^
                                            |   %esp fixup   | | 0.5 TiB
                                            |     stacks     | |
                        ffffff8000000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
           EFI_VA_END = ffffffef00000000 -> |----------------| ^
                                            |   EFI region   | | 64 GiB
                                            | mapping space  | |
         EFI_VA_START = ffffffff00000000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
   __START_KERNEL_map = ffffffff80000000 -> |----------------| ^
                                            |     Kernel     | |
                                            |      text      | | KERNEL_IMAGE_SIZE = 1 GiB *
                                            |     mapping    | |
        MODULES_VADDR = ffffffffc0000000 -> |----------------| x *
                                            |     Module     | |
                                            |    mapping     | | 1 GiB *
                                            |     space      | |
                        ffffffffff600000 -> |----------------| x
                                            |   vsyscalls    | | 8 MiB
                        ffffffffffe00000 -> |----------------| v
                                            /                /
                                            \     unused     \
                                            /      hole      /
                                            \                \
                                            ------------------

```

这几个图引自《linux-mm-notes》系列文章（链接忘了，在github上，搜一搜应该能找到）

注：如果PUD被标记为huge（1 GiB页面大小），则跳过PMD和PTE目录条目，直接通过PUD表项完成地址转换（并且将PUD视为PTE）；如果PMD被标记为huge（2 MiB页面大小），则跳过PTE目录条目，直接通过PMD表项完成地址转换。

至于每个页目录表项中的条目的每个flag位就更复杂了，此处略。


### linux中物理地址PA与虚拟地址VA的转换

1.  PA to VA:[\_\_va()](<https://elixir.bootlin.com/linux/v6.6/source/arch/x86/include/asm/page.h#L58>)

2.  VA to PA:[\_\_pa()](<https://elixir.bootlin.com/linux/v6.6/source/arch/x86/include/asm/page.h#L41>)

    我们只能转换部分直接映射的虚拟地址（ZONE\_DMA和ZONE\_NORMAL），即通过kmalloc()或\_\_get\_free\_pages()分配的内存，其余的（比如用户空间的地址；内核高端内存（ZONE\_HIGHMEM）、vmalloc区域或设备映射地址（需使用kmap()或ioremap()））都要通过页表去寻址。
    
    内核解压的关键步骤：
    
    ```C
    
    extract_kernel()
    ├── choose_random_location()  // 随机选择phys_base
    ├── handle_relocations()       // 调整虚拟地址偏移
    └── __startup_64()            // 验证物理/虚拟偏移一致性，__startup_64()中，通过比较physaddr参数与_text的实际物理地址计算load_delta
    
    ```
    
    ```C
    
    #define __pa(x)     __phys_addr((unsigned long)(x))
    
    #define __phys_addr(x)      __phys_addr_nodebug(x)
    
    static __always_inline unsigned long __phys_addr_nodebug(unsigned long x)
    {
            unsigned long y = x - __START_KERNEL_map;
    
            /* use the carry flag to determine if x was < __START_KERNEL_map */
            x = y + ((x > y) ? phys_base : (__START_KERNEL_map - PAGE_OFFSET));
    
            return x;
    }
    
    ```
    
    \_\_START\_KERNEL\_map是Linux内核中定义的一个关键宏，表示内核镜像的起始虚拟地址。（如x86\_64中通常为0xffffffff80000000），从虚拟地址中减去\_\_START\_KERNEL\_map，得到相对偏移量y。
    
    通过比较x与y的关系（即x > y是否成立）（即进位标志判断），确定虚拟地址是否位于内核直接映射区域（\_\_START\_KERNEL\_map以上的地址）。
    
    若虚拟地址在直接映射区（x > y），则加上phys\_base（物理内存的基址）。若在非直接映射区（如内核镜像区），则使用\_\_START\_KERNEL\_map - PAGE\_OFFSET作为修正偏移量
    
    [phys\_base](<https://elixir.bootlin.com/linux/v6.6/source/arch/x86/kernel/head64.c#L317>)表示从[CONFIG\_PHYSICAL\_START](<https://elixir.bootlin.com/linux/v6.6/source/arch/x86/Kconfig#L2065>)开始的物理偏移，如果内核已被重新定位，则内核text段映射进物理内存将从该偏移开始（在x86-64架构中默认值为0，但在启用KASLR时会被动态调整）。
    
    CONFIG\_PHYSICAL\_START是内核编译时预设的物理基地址，默认值为0x1000000（16MB）。这是内核镜像在链接阶段期望加载text段的物理起始地址。
    
    [load\_delta](<https://elixir.bootlin.com/linux/v6.6/source/arch/x86/kernel/head64.c#L203>)CONFIG\_PHYSICAL\_START与实际加载text段的地址（phys\_base）之间的差值，计算公式为：
    
    ```C
     /*
      * Compute the delta between the address I am compiled to run at
      * and the address I am actually running at.
      */
    load_delta = physaddr - (unsigned long)(_text - __START_KERNEL_map);
    ```


### 直接物理内存映射

物理内存是直接整个被映射进内核虚拟内存空间的，可以看上面讨论四级五级页表的内存空间排布的图。因此任何内核代码都可以访问物理内存的任何部分。

在初始化的时候就完成的。
`start_kernel() -> setup_arch() ->
init_mem_mapping()`


## 物理内存管理（伙伴系统）

TODO&#x2026;


## SLUB Internals

本篇文章这部分是学习内核堆利用时的视频笔记，视频源链接在最后。


### 基本概念：

Slab分配器：是用来管理内核堆内存的基础设施
目前linux内核提供三种主流的实现：SLOB，SLAB，SLUB，这三种提供相同的接口供外部使用。其中SLUB是linux默认启用的，也可以在编译前通过修改编译配置文件，换成其他两种。

objects：slab可以分配出去小内存区域。

slabs：是保存objects的大内存区域，其上区域被切分成大小相同的内存区域称为object slots。这片内存是通过page\_alloc分配的。

slot：是Slab分配器中预定义的 ​固定大小的内存块区间。

（slot和objects其实指代的东西相同，因为它们在内存上是重叠的，但是只是在不同场合他们的称呼不一样。区分不开问题也不大，理解工作流程即可。）


### Slab bugs

典型的动态内存bugs：

-   Out-of-bounds(OOB)越界读写

-   Use-after-free(UAF)

-   Double-free，invalid-free

攻击方式：

利用上述bug，可以达到overwrite和泄漏的目的。
因为free的object slot中存在元数据，我们可以通过覆盖链表的next指针，控制下一次的分配对象，获得任意地址读写，可以提权或者泄漏内核地址。堆上的内容也可能包含函数指针，我们可以控制它达成任意代码执行或者泄漏内核地址。具体的攻击措施还要看特定的漏洞详情。


### 内核堆上的防护措施：

下一个free slot的指针被保存在free slot的中间附近，这样可以防止小范围的溢出破坏指针

```C

cache->offset = ALIGN_DOWN(cache->object_size / 2, sizeof(void *));
freeptr_addr = (unsigned long)object + cache->offset;

```

通过一个 `CONFIG_SLAB_FREELIST_HARDENED=y` 的编译配置选项，freelist指针会被加密保存。

```C

cache->random = get_random_long();

freelist_ptr = (void *)((unsigned long)ptr ^  cache->random ^ swab(ptr_addr));
// ptr — actual value of freelist pointer
// ptr_addr — location where freelist pointer is stored
// swab() — exchanges adjacent even and odd bytes

```

ptr是freelist pointer的值，ptr\_addr是freelist pointer被保存的地址，swab交换奇偶byte字节序。

所以要利用只能先泄漏 `cache->random` 和 =ptr\_addr=，让利用更加困难。大多数现代 Slab 漏洞利用的是覆盖对象或者通过跨分配器攻击覆盖其他类型的内存。

通过 `CONFIG_SLAB_FREELIST_RANDOM=y` 配置，当分配新的 slab 时，SLUB 会打乱空闲列表中对象的顺序，这样让分配的地址更难预测。


### slab关键数据结构

1.  struct kmem\_cache

    ```C
    
    struct kmem_cache {
        // Per-CPU cache data:
        struct kmem_cache_cpu __percpu *cpu_slab;
        // Per-node cache data:
        struct kmem_cache_node *node[MAX_NUMNODES];
        ...
        const char *name; // Cache name
        slab_flags_t flags; // Cache flags
        unsigned int object_size; // Size of objects
        unsigned int offset; // Freelist pointer offset
        unsigned long min_partial;
        unsigned int cpu_partial_slabs;
    };
    
    ```
    
    比较关键的几个成员变量：
    
    name: 内核有许多不同的caches，可以通过 `cat /proc/slabinfo` 查看其中name就是第一列的名字，该name通过kmem\_cache\_create的参数指定
    
    object\_size: 也是通过kmem\_cache\_create的参数指定，每一个cache只可以分配固定大小的内存。
    
    cpu\_slab:
    SLUB分配器为每个CPU核心分配独立的kmem\_cache\_cpu结构，保存系统内特定cpu绑定的slab信息，目的是避免多核并发访问时的锁竞争。每个核心通过自己的kmem\_cache\_cpu直接从本地缓存分配内存对象。其内的slabs是绑定到特定CPU上的slab。在6.8版本以前也被称为froze  slabs，当CPU分配内存的时候，首先会从这些slabs中分配。
    
    node：是为每个NUMA节点保存slab信息。NUMA的核心思想是把CPU分组，来简化资源的分配的复杂性。相当于拥有一个全局的slabs列表，尚未绑定到任何CPU，但是也仍然属于cache，也会包含已经分配的objects。
    
    结构体详情：
    
    ```C
    
    struct kmem_cache_cpu {
        struct slab *slab;    // Active slab
        struct slab *partial; // Partial slabs
        ...
    };
    struct kmem_cache_node {
        struct list_head partial; // Slabs
        ...
    };
    
    ```

2.  per-CPU

    对于 `struct slab` 的简化信息：
    
    ```C
      struct slab {  // Aliased with struct page
          struct kmem_cache *slab_cache; // Cache this slab belongs to
          struct slab *next; // Next slab in per-cpu list
          int slabs; // Slabs left in per-cpu list
          struct list_head slab_list; // List links in per-node list
          void *freelist; // Per-slab freelist
          ...
    };
    
    ```
    
    slab是一个 struct slab 的结构体，上述是简化的版本，struct slab 别名为struct page，提到这就不得不提一下历史了，在Linux内核5.17版本中，struct slab被引入，目的是将slab相关的字段从struct page中分离出来。struct page（每一个物理页面都有一个相应的page对应）之前包含了很多不同用途的字段，使用union来适应不同场景，导致结构复杂。现在struct slab作为struct page的一个overlay，共享同一块内存，但隐藏了struct page的细节，这样slab分配器只需要处理自己的结构。
    
    slab\_cache指向自己属于的cache。
    
    每一个slab都有后备内存，后备内存是通过page\_alloc想buddy system分配。不需要指针指向它，struct slab本身就是一个struct page
    
    包含object slots，[size](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L4137>)是基于objects大小计算出来的。
    
    freelist指针指向第一个slab中free的slot，下一个free slot的指针被保存在free slot中。freelist最后一个指针是NULL，objects都是从链表头分配，free也是插入链表头。
    
    full slabs是指没有free slot的slab，此时它的freelist 指针是NULL。
    
    多个slab可以用链表结构串联在一起。per-CPU的是单链表， `struct slab` 中的 `next` 指针，per-node的是双链表， `struct slab` 中的 `list_head slab_list` 。

3.  active slab

    先来看下kmem\_cache\_cpu的active slab，per-CPU的slabs的其中之一被设计成激活的，并把slab成员指针赋值为该slab。分配object的时候会首先从这个slab中分配。
    
    active slab有两个freelists。 `kmem_cache_cpu->freelist` 和 `kmem_cache_cpu->slab->freelist` 都指向它的slots。但是两个链表并不相交，
    `kmem_cache_cpu->freelist` 用来给绑定的CPU分配释放内存的。
    
    `kmem_cache_cpu->slab->freelist` 被用来给其他CPUs分配释放内存的（这个模块的代码有可能不只在一个cpu上运行，可能会在任务切换过程中跑到其他cpu上执行了）。

4.  partial slabs

    partial意思是这些slab有空闲slot（至少有一个，也有可能是fully free）。
    
    每个partial slabs都有后备内存。
    
    只有一个freelist，
    
    只在active slab变为full后被使用。
    
    per-CPU partial slabs的列表最大数量是有限的，这个大小是由kmem\_cache->cpu\_partial\_slabs字段指定，这个值是根据object和slab的大小计算出来的[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L4364>) 用户空间是无法查看这个字段值的，只能查看 `/sys/kernel/slab/$CACHE/cpu_partial` ，然后自己计算出cpu\_partial\_slabs。

5.  per-node

    kmem\_cache\_node 有一个per-node partial slabs的列表。这就意味这每一个都至少有一个free slots。
    
    每一个都有后备内存和一个freelist。
    
    一旦per-CPU中的slabs都用完都变成full后他们就会被使用。
    
    per-node slabs 的最小数量也是有限制的。由kmem\_cache->min\_partial指定， 计算也是基于object的大小[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L4543>)
    
    可以在用户空间中查看 `/sys/kernel/slab/$CACHE/min_partial` 

6.  full slabs

    full slabs 不会被tracked。没有指针指向full slabs（除非开启slub\_debug），一旦任意一个object被释放到full slab中，分配器会获得指向该slab的指针。我们只需使用[virt\_to\_slab](<https://elixir.bootlin.com/linux/v6.6/source/mm/slab.h#L211>)计算。


### 分配过程

为了方便介绍，这里分为五个不同层次的分配过程

1.  1. allocating from lockless per-CPU freelist kmem\_cache\_cpu->freelist

    当无锁的该cpu slab的freelist是不为空，那么就会分配该freelist的第一个object
    
    如果为空，goto 2。

2.  2. allocating from active slab (kmem\_cache\_cpu->slab->freelist)

    如果active slab freelist不是空的，
    
    首先move active slab freelist到 lockless per-CPU freelist；[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3151>)
    
    然后从这个lockless的per-CPU freelist分配第一个object。[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3176>)并更新这个freelist[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3173>)
    
    如果这个active slab freelist为空。 goto 3[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3158>)

3.  3. allocating from per-CPU partial slabs (kmem\_cache\_cpu->partial)

    如果有per-CPU的partial slabs：
    
    首先将链表中的第一个脱链，并指定为active slabs [link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3206>)
    
    goto 2[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3210>)
    
    如果per-CPU的partial slabs是空的
    
    goto 4[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3213>)

4.  4. allocating from per-node partial slabs (kmem\_cache\_node->partial)

    如果有per-node的partial slabs：
    首先将链表中的第一个脱链，并指定为active slabs[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2309>)；然后移动一些(最多cpu\_partial\_slabs / 2[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2319>))per-node的slabs到per-CPU的partial list[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2313>)；再去active slab重新分配。[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3220>)
    
    如果per-node partial list 为空，goto 5

5.  5. Create new slab

    [allocate](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3223>) from new slab的过程：
    
    首先从page\_alloc中分配新的slab，并放进freelist中，并指定为active slab，然后从该slab中分配对象。


### explotion case

1.  Out-of-bounds, case #1 (Shaping Slab memory)
    
    攻击所需条件：
    
    1.  需要一个内核bug能导致OOB；
    2.  有两个不同的系统调用，一个可以分配object(IOCTL\_ALLOC)，一个可以OOB(IOCTL\_OOB)；
    3.  能够leak或者overwrite的目标object；
    4.  能将可利用的object和targetobject挨着放在一起。
    
    攻击过程：
    
    1.  allocate 足够的targt objects 来获取新的active slab；需要填充所有的holes达到分配过程的第五步。
        
        所以我们就需要找到有多少个holes。
        但是在非特权的目标系统上，没有方法能够找到确切的数目。 `/proc/slabinfo` 和相关文件对于普通用户不可读。
        
        而且我们可能拥有的空闲插槽数量没有上限，原因是atcive slab上的holes数量最多有每一个slab上的objects的数目。
        per-CPU partials的holes数量上限是每一个slab上的objects的数目 x cpu\_partial\_slabs。
        per-node partials的没有限制slabs的数量。

所以一种方式是估计，首先重现目标环境，运行相同的版本内核，运行相同的软件，然后我们通过 `cat /proc/slabinfo` 看有多少个holes。

还有一种[基于时间信道](<https://stefangast.eu/papers/slubstick.pdf>)的方式。

| name | <active\_objs> | <num\_objs> | <objsize> | <objperslab> | <pagesperslab> |
|---|---|---|---|---|---|
| cred\_jar | 7644 | 7644 | 192 | 21 | 1 |
| kmalloc-8k | 456 | 460 | 8192 | 4 | 8 |
| kmalloc-4k | 3118 | 3160 | 4096 | 8 | 8 |
| kmalloc-2k | 3621 | 3696 | 2048 | 16 | 8 |
| kmalloc-32 | 54789 | 55808 | 32 | 128 | 1 |

active\_objs: 已经分配的objects的数量，
num\_objs: 现存slab中的slots的总数。
这个值不是实时更新的，只有在一个slab被分配，释放或者移动到per-node partial list时才会更新。

Shrink cache 可以获得更准确的值，

`echo 1 | sudo tee /sys/kernel/slab/kmalloc-32/shrink`

但是这样会导致这个cache释放fully free slabs。

| # name | <active\_objs> | <num\_objs> |
|---|---|---|
| kmalloc-32 | 25216 | 25216     // Before shrinking. |
| kmalloc-32 | 23132 | 24320     // After shrinking. |

比如这个就少了1000多个，这个就是不准确的，即是我们复制来环境也不准确。

1.  现在假设我们分配了足够的target objects并获得了一个新的active slab。并且新的active slab被target objects填充一部分；

2.  现在通过IOCTL\_ALLOC操作分配一个vulnerable object；
    现在分配足够的target objects填满active slab。现在slab变成full，尽管可能会变成非active，但是没关系。
    
    现在内存看起来是这样：
    
    ```C
    +-------+-------+-------+-------+-------+-------+-------+-------+
    | Target| Target| Target| Vuln  | Target| Target| Target| Target|
    +-------+-------+-------+-------+-------+-------+-------+-------+
    
    ```

3.  现在通过IOCTL\_OOB触发越界访问。

```C
+-------+-------+-------+-------+-------+-------+-------+-------+
| Target| Target| Target| Vuln  | Target| Target| Target| Target|
+-------+-------+-------+-------+-------+-------+-------+-------+
                            |_______| OOB
```

（注：如果没有第一步，我们就无法破坏target，并且可能会破坏内核其他数据，后果不可控。所以第一步是为了explition的稳定。
除此之外这个exp也有一些问题，比如:
如果vuln被allocated到最后一个object，这就有概率会失败。解决的办法就是在其后多分配一个slab，然后填充target。
Migration: 进程被移动到另一个CPU上执行了。解决办法：绑定CPU的亲和性
Preempting: 另一个进程或者中断处理来抢占此CPU，解决方法：减少slab shaping的时间；使用less noisy（不那么频繁） 的cache。）

1.  Out-of-bounds, case #2 （Shaping Slab memory）
    
    需要条件：分配vulnerable objects并且立即写数据触发OOB（IOCTL\_ALLOC\_AND\_OOB），
    
    攻击过程：
    
    1.  分配足够多的target objects以获得新的 active slab；
    
    2.  分配一个vulnerable object并且触发OOB通过IOCTL\_ALLOC\_AND\_OOB，
        
        这有两种情况，
        case #1: OOB访问的区域在free slot中，如果OOB的范围很小，没有覆盖元数据，则不会发生任何事情。可以重复进行OOB操作。
        
        ```C
        +-------+-------+-------+-------+-------+-------+-------+-------+
        | Target|       | Target| Vuln  |       | Target| Target| Target|
        +-------+-------+-------+-------+-------+-------+-------+-------+
                                    |_______| OOB
        ```

case #2: OOB访问的区域在target object中

Success！！！ 但是也许需要很多次重试才能成功

```C
+-------+-------+-------+-------+-------+-------+-------+-------+
| Target|       | Target| Vuln  | Target| Target| Target| Target|
+-------+-------+-------+-------+-------+-------+-------+-------+
                            |_______| OOB
```


### Freeing process and explition

1.  case #1: object 属于active slab，
    
    object加入无锁的per-CPU的freelist的头部。[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3766>)
    
    想象一种场景:
    
    ```C
    void *ptr1 = kmalloc(128, GFP_KERNEL);
    free(ptr1);
    void *ptr2 = kmalloc(128, GFP_KERNEL);
    free(ptr2);
    void *ptr3 = kmalloc(128, GFP_KERNEL);
    
    ```
    
    ptr1，ptr2，ptr3都指向同一个object。
    
    所以这就引出第一种利用场景(UAF)
    
    所需条件：假设我们有UAF的漏洞：
    
    1.  分配vulnerable object （IOCTL\_ALLOC）
    
    2.  free vulnerable object （IOCTL\_FREE）
    
    3.  在IOCTL\_FREE后，读写vulnerable object的数据，（IOCTL\_UAF）
    
    攻击过程：
    
    1.  通过IOCTL\_ALLOC分配一个vulnerable object，
    
    2.  通过IOCTL\_FREE free vulnerable object，悬空引用仍然存在；
    
    3.  分配一个target object，现在那个悬空指针指向它；
    
    4.  现在能够使用IOCTL\_UAF触发UAF访问。

2.  case #2: object属于一个non-full slab
    
    free object到所属的freelist之中。[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3661>)
    
    如果slab是per-node的，并且变成了fully free，并且node有足够的per-node slabs。该slab会被从per-node中移除并[free](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3687>)回page allocator中。
    
    如果object属于non-full non-current-active slab：[free](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3661>)object 到slab freelist中可能会[free] (<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3687>)per-node的full slab，但是[不适用于](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3666>)per-CPU partial或者active slabs（即使变成full free也不会free回page\_alloca，仍然待在相应列表中） 
    
    如果object属于另一个CPU的active slab，将会把它放到active slab的freelist（不是per-CPU的freelist）中[link](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3661>)。

1.  case #3: object 属于full slab
    
    [free](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3661>) object 到slab fresslist
    
    [move](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3679>) slab到per-CPU的partial list：
    
    如果per-CPU的partial list[没满](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2716>)（<cpu\_partial\_slabs），就把它放到链表头中。
    
    如果per-CPU的partial list已经[满了](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2708>)（>=cpu\_partial\_slabs），free\_up per-CPU partial list遍历链表并执行执行以下操作
    
    [Move](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2642>) per-CPU slabs 到per-node list的尾部，
    
    [free](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2655>) full freed per-CPU slabs 到page\_alloc中（可用于cross-cache的攻击）
    
    直到per-node 的slabs的数量达到min\_partial
    
    现在per-CPU的partial list有空间了，将该slab[放进](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2726>)链表头中


### explition case

1.  OOB变UAF
    
    所需条件：1)分配vulnerable object（IOCTL\_ALLOC）
    
    2)可以越界向vulnerable object写数据。

攻击流程：slab已经经过我们的shaping成full slab，并且有一个OOB的vuln object。如果我们现在有一个Vuln的object可以OOB，我们把它在内存上挨着的下一个object视为target object，target object有引用计数之类的东西，通过溢出后就可以控制引用计数，原来的程序会在错误的时机free target object然后我们就可以将target object变成一个UAF。并且该slab会被添加到per-CPU的partial list的头部

（注：在shaping slab的时候，我们可以用slab spraying的方式：分配很多的objects，所以问题就是我们需要spray多少个object，这个数量需要根据实际情况来看。）

1.  allocation和OOB组合在一起
    
    所需条件：1) allocate vulnerable object并且立即写入OOB数据（IOCTL\_ALLOC\_AND\_OOB）
    
    攻击流程：
    
    1.  分配足够的target objects能获取新的active slab，
    
    2.  分配更多的target objects去填充这个slab，直到slab变成full，
    
    3.  从这个slab中free一个target object，
    
    4.  现在我们重新使用这个free slot，并且使用IOCTL\_ALLOC\_AND\_OOB去溢出内存中挨着的下一个targe object。

1.  double-free
    
    `CONFIG_SLAB_FREELIST_HARDENED=y` 开启这个编译选项后，double-free会被[检测](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L448>)到


### 总结

slub机制是十分复杂的，并且其中还有很多的情况和优化需要考虑，本文只是浅浅涉猎一下。

[SLUB source](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c>)

[\_\_slab\_alloc\_node](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3329>)allocation 过程开始的地方

[do\_slab\_free](<https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3734>)free 过程开始的地方


### 拓展阅读

[Freeing free slot via double-free can be used for cross-cache attacks](<https://arxiv.org/pdf/2406.02624>)

More details about how SLUB works:[Linux SLUB Allocator Internals and Debugging](<https://blogs.oracle.com/linux/post/linux-slub-allocator-internals-and-debugging-1>)[note](<https://lore.kernel.org/linux-mm/c71a884d-714f-4741-906f-4df162bde303@suse.cz/>)

About cache merging, accounting, and hardened usercopy:[Linux kernel heap feng shui in 2022](<https://duasynt.com/blog/linux-kernel-heap-feng-shui-2022>)

Introduction to cross-cache use-after-free attacks:[CVE-2022-29582, An io\_uring vulnerability](<https://ruia-ruia.github.io/2022/08/05/CVE-2022-29582-io-uring/>)

Improving reliability of Slab shaping:

[Playing for K(H)eaps: Understanding and Improving Linux Kernel Exploit Reliability](<https://haehyun.github.io/papers/playing-for-keaps-22-sec.pdf>)

[PSPRAY: Timing Side-Channel based
Linux Kernel Heap Exploitation Technique](<https://www.usenix.org/system/files/sec23summer_79-lee-prepub.pdf>)

[SLUBStick: Arbitrary Memory Writes through
Practical Software Cross-Cache Attacks within the Linux Kernel](<https://stefangast.eu/papers/slubstick.pdf>)


### 参考链接

[SLUB演讲视频连接](<https://www.youtube.com/watch?v=XulsBDV4n3w>)

[PPT](<https://static.sched.com/hosted_files/lsseu2024/37/2024,%20LSS%20EU_%20SLUB%20Internals%20for%20Exploit%20Developers.pdf>)
