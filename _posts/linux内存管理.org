#+TITLE: Linux内存管理
#+DATE: 2025-03-15
#+JEKYLL_LAYOUT: post
#+JEKYLL_CATEGORIES: PWN,linux
#+JEKYLL_TAGS: PWN,linux



本篇文章详细介绍linux内核的内存管理，主要分为两部分，介绍伙伴算法和slab分配器-SLUB的工作机制，重点放在后面部分。

我们说的内存管理器是指 =page allocator= 与 =slab allocator= ：

page allocator: 负责管理整个系统的物理内存的分配，linux的page分配器基于伙伴系统buddy system

slab allocator: 负责堆内存分配，有很多种，我们主要谈论SLUB的实现。

我们可以通过 =cat /proc/buddyinfo= 与 =cat /proc/pagetypeinfo= 查看页面相关信息：

** CPU的分页机制
一切的一切从CPU的分页机制谈起...


由于物理内存管理使用页表结构会根据芯片架构的不同而有所不同，这里以x86-64架构为例来介绍：

*** Virtual memory layout


[Kernel address space]https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt


cpu有一个CR3寄存器存放第一级页表（PGD）的物理地址。页表中的每一个表项(后面简称entry)必须要4KB大小对齐。
每一个page table entry 都是一个 =unsigned long(uint64_t)(declared as pxxval_t)= 类型的值，通过将这些类型中的每一个封装在一个结构体中，可以强制执行一些makeshift类型安全比如 =typedef struct { pgdval_t pgd; } pgd_t= 。PageTable的结构依赖于Intel 5-level paging是否开启，检查方式在[check_la57_support()](https://elixir.bootlin.com/linux/v6.6/source/arch/x86/kernel/head64.c#L105)。

虚拟地址空间是由 [__VIRTUAL_MASK](https://elixir.bootlin.com/linux/v6.6/source/arch/x86/include/asm/page_types.h#L14)和[__VIRTUAL_MASK_SHIFT](https://elixir.bootlin.com/linux/v6.6/source/arch/x86/include/asm/page_64_types.h#L57)决定的。

=#define __VIRTUAL_MASK		((1UL << __VIRTUAL_MASK_SHIFT) - 1)=

=#define __VIRTUAL_MASK_SHIFT	(pgtable_l5_enabled() ? 56 : 47)=

| Level | Count                        | Shift                          | Description                |
|-------+------------------------------+--------------------------------+----------------------------|
| PGD   | [PTRS_PER_PGD][6] (512)      | [PGDIR_SHIFT][13] (48 or 39)   | Page Global Directory      |
| P4D   | [PTRS_PER_P4D][7] (512 or 1) | [P4D_SHIFT][14] (39)           | Page 4 Directory()         |
| PUD   | [PTRS_PER_PUD][10] (512)     | [PUD_SHIFT][14] (30)           | Page Upper Directory       |
| PMD   | [PTRS_PER_PMD][11] (512)     | [PMD_SHIFT][15] (21)           | Page Middle Directory      |
| PTE   | [PTRS_PER_PTE][12] (512)     | [PAGE_SHIFT][16] (12)          | Page Table Entry directory |

以下是分别在4级5级页表结构中虚拟地址的各个位在寻址时代表在各级目录表项的索引。

在 4 级页表的 x86-64 架构中，虚拟地址空间为 48 位。

#+BEGIN_SRC C

  
                                      48 bits
  <--------------><---------------------------------------------->
     6         5         4         3         2         1
  ---|---------|---------|---------|---------|---------|----------
  3210987654321098765432109876543210987654321098765432109876543210
                  [  PGD  ][  PUD  ][  PMD  ][  PTE  ][  OFFSET  ]
  111111111111111111111111111111111111111111100000000|000000000000  PMD_MASK
  111111111111111111111111111111111100000000|00000000|000000000000  PUD_MASK
  111111111111111111111111100000000|00000000|00000000|000000000000  PGDIR_MASK
                          |        |        |        |
                          |        |        |        |
                          |        |        |        |------------- PAGE_SHIFT  (12)
                          |        |        |---------------------- PMD_SHIFT   (21)
                          |        |------------------------------- PUD_SHIFT   (30)
                          |---------------------------------------- PGDIR_SHIFT (39)
#+END_SRC

~512 * 1 * 512 * 512 * 512 = 68.7bn 4KiB pages = 256 TiB~ ，四级页表模式可以寻址空间在256TB

地址空间排布

#+BEGIN_SRC C
  Userland (128 TiB)
                          0000000000000000 -> |---------------| ^
                                              |    Process    | |
                                              |    address    | | 128 TiB
                                              |     space     | |
                          0000800000000000 -> |---------------| v
                       .        ` .     -                 `-       ./   _
                                _    .`   -   The netherworld of  `/   `
                      -     `  _        |  /      unavailable sign-extended -/ .
                       ` -        .   `  48-bit address space  -     \  /    -
                     \-                - . . . .             \      /       -
  Kernel (128 TiB)
                          ffff800000000000 -> |----------------| ^
                                              |   Hypervisor   | |
                                              |    reserved    | | 8 TiB
                                              |      space     | |
                          ffff880000000000 -> |----------------| x
                                              | LDT remap for  | | 0.5 TiB
                                              |       PTI      | |
  [kaslr]   PAGE_OFFSET = ffff888000000000 -> |----------------| x
                                              | Direct mapping | |
                                              |  of all phys.  | | 64 TiB
                                              |     memory     | |
                          ffffc88000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
  [kaslr] VMALLOC_START = ffffc90000000000 -> |----------------| ^
                                              |    vmalloc/    | |
                                              |    ioremap     | | 32 TiB
                                              |     space      | |
        VMALLOC_END + 1 = ffffe90000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
  [kaslr] VMEMMAP_START = ffffea0000000000 -> |----------------| ^
                                              |     Virtual    | |
                                              |   memory map   | | 1 TiB
                                              |  (struct page  | |
                                              |     array)     | |
                          ffffeb0000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
                          ffffec0000000000 -> |----------------| ^
                                              |  KASAN shadow  | | 16 TiB
                                              |     memory     | |
                          fffffc0000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
                          fffffe0000000000 -> |----------------| ^
                                              | cpu_entry_area | | 0.5 TiB
                                              |     mapping    | |
                          fffffe8000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
       ESPFIX_BASE_ADDR = ffffff0000000000 -> |----------------| ^
                                              |   %esp fixup   | | 0.5 TiB
                                              |     stacks     | |
                          ffffff8000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
             EFI_VA_END = ffffffef00000000 -> |----------------| ^
                                              |   EFI region   | | 64 GiB
                                              | mapping space  | |
           EFI_VA_START = ffffffff00000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
     __START_KERNEL_map = ffffffff80000000 -> |----------------| ^
                                              |     Kernel     | |
                                              |      text      | | KERNEL_IMAGE_SIZE = 1 GiB *
                                              |     mapping    | |
          MODULES_VADDR = ffffffffc0000000 -> |----------------| x *
                                              |     Module     | |
                                              |    mapping     | | 1 GiB *
                                              |     space      | |
                          ffffffffff600000 -> |----------------| x
                                              |   vsyscalls    | | 8 MiB
                          ffffffffffe00000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
                                              ------------------
      

#+END_SRC


在 5 级页表的 x86-64 架构中，虚拟地址空间扩展到了 57 位。

#+BEGIN_SRC C


                                 57 bits
  <-----><------------------------------------------------------->
     6         5         4         3         2         1
  ---|---------|---------|---------|---------|---------|----------
  3210987654321098765432109876543210987654321098765432109876543210
         [  PGD  ][  P4D  ][  PUD  ][  PMD  ][  PTE  ][  OFFSET  ]
  111111111111111111111111111111111111111111100000000|000000000000  PMD_MASK
  111111111111111111111111111111111100000000|00000000|000000000000  PUD_MASK
  111111111111111111111111100000000|00000000|00000000|000000000000  P4D_MASK
  111111111111111100000000|00000000|00000000|00000000|000000000000  PGDIR_MASK
                 |        |        |        |        |
                 |        |        |        |        |------------- PAGE_SHIFT  (12)
                 |        |        |        |---------------------- PMD_SHIFT   (21)
                 |        |        |------------------------------- PUD_SHIFT   (30)
                 |        |---------------------------------------- P4D_SHIFT   (39)
                 |------------------------------------------------- PGDIR_SHIFT (48)

#+END_SRC

~512 * 512 * 512 * 512 * 512` = 35.2tn 4KiB pages = 128 PiB~ ，五级页表模式可以寻址空间在128PB

#+BEGIN_SRC C
  Userland (64 PiB)
                          0000000000000000 -> |---------------| ^
                                              |    Process    | |
                                              |    address    | | 64 PiB
                                              |     space     | |
                          0100000000000000 -> |---------------| v
                       .        ` .     -                 `-       ./   _
                                _    .`   -   The netherworld of  `/   `
                      -     `  _        |  /      unavailable sign-extended -/ .
                       ` -        .   `  57-bit address space  -     \  /    -
                     \-                - . . . .             \      /       -
  Kernel (64 PiB)
                          ff00000000000000 -> |----------------| ^
                                              |   Hypervisor   | |
                                              |    reserved    | | 4 PiB
                                              |      space     | |
                          ff10000000000000 -> |----------------| x
                                              | LDT remap for  | | 0.25 PiB
                                              |       PTI      | |
  [kaslr]   PAGE_OFFSET = ff11000000000000 -> |----------------| x
                                              | Direct mapping | |
                                              |  of all phys.  | | 32 PiB
                                              |     memory     | |
                          ff91000000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
  [kaslr] VMALLOC_START = ffa0000000000000 -> |----------------| ^
                                              |    vmalloc/    | |
                                              |    ioremap     | | 12.5 PiB
                                              |     space      | |
        VMALLOC_END + 1 = ffd2000000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
  [kaslr] VMEMMAP_START = ffd4000000000000 -> |----------------| ^
                                              |     Virtual    | |
                                              |   memory map   | | 0.5 PiB
                                              |  (struct page  | |
                                              |     array)     | |
                          ffd6000000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
                          ffdf000000000000 -> |----------------| ^
                                              |  KASAN shadow  | | 8 PiB
                                              |     memory     | |
                          fffffc0000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
                          fffffe0000000000 -> |----------------| ^
                                              | cpu_entry_area | | 0.5 TiB
                                              |     mapping    | |
                          fffffe8000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
       ESPFIX_BASE_ADDR = ffffff0000000000 -> |----------------| ^
                                              |   %esp fixup   | | 0.5 TiB
                                              |     stacks     | |
                          ffffff8000000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
             EFI_VA_END = ffffffef00000000 -> |----------------| ^
                                              |   EFI region   | | 64 GiB
                                              | mapping space  | |
           EFI_VA_START = ffffffff00000000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
     __START_KERNEL_map = ffffffff80000000 -> |----------------| ^
                                              |     Kernel     | |
                                              |      text      | | KERNEL_IMAGE_SIZE = 1 GiB *
                                              |     mapping    | |
          MODULES_VADDR = ffffffffc0000000 -> |----------------| x *
                                              |     Module     | |
                                              |    mapping     | | 1 GiB *
                                              |     space      | |
                          ffffffffff600000 -> |----------------| x
                                              |   vsyscalls    | | 8 MiB
                          ffffffffffe00000 -> |----------------| v
                                              /                /
                                              \     unused     \
                                              /      hole      /
                                              \                \
                                              ------------------
      
#+END_SRC


这几个图引自《linux-mm-notes》系列文章（链接忘了，在github上，搜一搜应该能找到）

注：如果PUD被标记为huge（1 GiB页面大小），则跳过PMD和PTE目录条目，直接通过PUD表项完成地址转换（并且将PUD视为PTE）；如果PMD被标记为huge（2 MiB页面大小），则跳过PTE目录条目，直接通过PMD表项完成地址转换。

至于每个页目录表项中的条目的每个flag位就更复杂了，此处略。


*** linux中物理地址PA与虚拟地址VA的转换

**** PA to VA:[__va()](https://elixir.bootlin.com/linux/v6.6/source/arch/x86/include/asm/page.h#L58)


**** VA to PA:[__pa()](https://elixir.bootlin.com/linux/v6.6/source/arch/x86/include/asm/page.h#L41)


我们只能转换部分直接映射的虚拟地址（ZONE_DMA和ZONE_NORMAL），即通过kmalloc()或__get_free_pages()分配的内存，其余的（比如用户空间的地址；内核高端内存（ZONE_HIGHMEM）、vmalloc区域或设备映射地址（需使用kmap()或ioremap()））都要通过页表去寻址。

内核解压的关键步骤：

#+BEGIN_SRC C

  extract_kernel()
  ├── choose_random_location()  // 随机选择phys_base
  ├── handle_relocations()       // 调整虚拟地址偏移
  └── __startup_64()            // 验证物理/虚拟偏移一致性，__startup_64()中，通过比较physaddr参数与_text的实际物理地址计算load_delta

#+END_SRC


#+BEGIN_SRC C

  #define __pa(x)     __phys_addr((unsigned long)(x))

  #define __phys_addr(x)      __phys_addr_nodebug(x)

  static __always_inline unsigned long __phys_addr_nodebug(unsigned long x)
  {
  	unsigned long y = x - __START_KERNEL_map;

  	/* use the carry flag to determine if x was < __START_KERNEL_map */
  	x = y + ((x > y) ? phys_base : (__START_KERNEL_map - PAGE_OFFSET));

  	return x;
  }

#+END_SRC


__START_KERNEL_map是Linux内核中定义的一个关键宏，表示内核镜像的起始虚拟地址。（如x86_64中通常为0xffffffff80000000），从虚拟地址中减去__START_KERNEL_map，得到相对偏移量y。

通过比较x与y的关系（即x > y是否成立）（即进位标志判断），确定虚拟地址是否位于内核直接映射区域（__START_KERNEL_map以上的地址）。

若虚拟地址在直接映射区（x > y），则加上phys_base（物理内存的基址）。若在非直接映射区（如内核镜像区），则使用__START_KERNEL_map - PAGE_OFFSET作为修正偏移量

[phys_base](https://elixir.bootlin.com/linux/v6.6/source/arch/x86/kernel/head64.c#L317)表示从[CONFIG_PHYSICAL_START](https://elixir.bootlin.com/linux/v6.6/source/arch/x86/Kconfig#L2065)开始的物理偏移，如果内核已被重新定位，则内核text段映射进物理内存将从该偏移开始（在x86-64架构中默认值为0，但在启用KASLR时会被动态调整）。

CONFIG_PHYSICAL_START是内核编译时预设的物理基地址，默认值为0x1000000（16MB）。这是内核镜像在链接阶段期望加载text段的物理起始地址。

[load_delta](https://elixir.bootlin.com/linux/v6.6/source/arch/x86/kernel/head64.c#L203)CONFIG_PHYSICAL_START与实际加载text段的地址（phys_base）之间的差值，计算公式为：

#+BEGIN_SRC C
   /*
    * Compute the delta between the address I am compiled to run at
    * and the address I am actually running at.
    */
  load_delta = physaddr - (unsigned long)(_text - __START_KERNEL_map);
#+END_SRC



*** 直接物理内存映射

物理内存是直接整个被映射进内核虚拟内存空间的，可以看上面讨论四级五级页表的内存空间排布的图。因此任何内核代码都可以访问物理内存的任何部分。

在初始化的时候就完成的。
=start_kernel() -> setup_arch() ->
init_mem_mapping()=



** 物理内存管理（伙伴系统）

#+BEGIN_SRC C

  pg_data_t
    └── node_zones
        ├── ZONE_DMA
        │   └── zone_mem_map
        │       ├── struct page
        │       ├── struct page
        │       └── struct page
        ├── ZONE_NORMAL
        │   └── zone_mem_map
        │       ├── struct page
        │       ├── struct page
        │       └── struct page
        └── ZONE_HIGHMEM
            └── zone_mem_map
                ├── struct page
                ├── struct page
                └── struct page

#+END_SRC



*** 基本概念：


**** node（节点）

这个概念跟内存控制器（MC）有关，如果系统中的CPU很多，为了简化内存资源的分配以及提高利用效率，CPU设计会有多个内存控制器，共用相同内存控制器的CPU组为一个node。分为UMA和NUMA架构，前者只有一个节点，只有一个内存控制器，后者将分为多个节点，每个节点有一个内存控制器。（为了降低认知负载，我们就只讨论UMA架构的）。对应结构体[pglist_data](https://elixir.bootlin.com/linux/v6.6/source/include/linux/mmzone.h#L1261)

全局变量[node_data](https://elixir.bootlin.com/linux/v6.6/source/arch/x86/mm/numa.c#L25)来保存各个node的信息。

结构体中 =node_zones= 作为一个 zone 结构体数组，记录了本节点上所有的 zone，其中可用的 zone 的个数由节点结构体的 =nr_zones= 字段限制。

=node_zonelists= ：内存分配时备用 zone 的搜索顺序

=node_start_pfn= ：node 的起始页框标号

=node_present_pages= ：node 中物理页的总数量

=unsigned long node_spanned_pages= ： node 中物理页的总大小

=node_id= ：node 的标号

在 =/mm/page_alloc.c= 中定义了一个全局数组 [node_states ](https://elixir.bootlin.com/linux/v6.6/source/mm/page_alloc.c#L191)用以标识对应标号的节点的状态，结构体中的 [nodemask_t](https://elixir.bootlin.com/linux/v6.6/source/include/linux/nodemask.h#L99) 类型为一个位图类型，定义于  =/include/linux/nodemask.h= 中
。这个状态由一个枚举类型 [node_states](https://elixir.bootlin.com/linux/v6.6/source/include/linux/nodemask.h#L398) 定义，该枚举类型定义于 /include/linux/nodemask.h
使用这个命令来查看系统中的节点信息： =numactl --hardware=



**** zone（区）

节点之下便是zone，zone代表的是内存的用途，把内存划分区域管理，不同用途的内存页属于不同的zone。对应结构体[zone](https://elixir.bootlin.com/linux/v6.6/source/include/linux/mmzone.h#L810)

zone的类型：

1. ​ZONE_DMA

​用途：专供DMA（直接内存访问）设备使用。这类设备无法通过CPU的虚拟地址直接访问内存，因此需要物理地址连续的页面。
​物理内存范围：通常为0~16MB（具体范围可能因架构和内核配置而异）。例如，在IA32架构中，ZONE_DMA固定管理前16MB内存。
​适用场景：如旧式网卡、磁盘控制器等仅支持DMA且寻址能力有限的硬件。

2. ​ZONE_DMA32

​用途：扩展的DMA区域，支持32位地址总线的DMA设备访问更大的内存范围（如4GB以内）。
​物理内存范围：0~4GB，需内核启用CONFIG_ZONE_DMA32配置。例如，在ARM64平台中，若内存总量≤4GB，则所有内存可能被划入此区域。
​与ZONE_DMA的区别：ZONE_DMA32允许更大范围的物理地址，适用于现代DMA设备。

3. ​ZONE_NORMAL

​用途：常规内存区域，供内核和进程直接映射使用。此区域的物理地址可通过内核的线性映射直接访问，无需特殊处理。
​物理内存范围：在IA32架构中为16MB~896MB，而在ARM64等64位架构中可能覆盖4GB以上的内存（需内核配置支持）。
​重要性：大多数内核数据结构和用户进程的匿名页（如堆、栈）分配于此区域。

4. ​ZONE_HIGHMEM

​用途：管理高端内存（物理地址超过内核线性映射范围的区域）。此类页面需通过动态映射（如kmap）才能被内核临时访问。
​物理内存范围：在32位系统中通常为896MB~4GB。64位系统因虚拟地址空间充足，一般不启用此区域。
​适用性：主要用于32位系统的大内存支持，例如处理用户空间的大型文件映射。

5. 其他可选Zone类型

​ZONE_MOVABLE:用于可迁移的页面，支持内存热插拔或减少内存碎片。此类页面可通过迁移调整物理位置。

​ZONE_DEVICE:专为持久化内存设备（如NVDIMM）设计，支持设备内存的特殊访问模式


重要的字段：

=_watermark= ：“水位线”

每一个 zone 都有着其对应的三档“水位线”： WMARK_MIN、WMARK_LOW、WMARK_HIGH，存放在 _watermark 数组中，在进行内存分配时，分配器（例如 buddy system）会根据当前 zone 中空余内存所处在的“水位线”来判断当前的内存状况，如下图所示：

=lowmem_reserve= ：zone 自身的保留内存

在进行内存分配时，若当前的 zone 没有足够的内存了，则会向下一个 zone 索要内存，那么这就存在一个问题：来自 higher zones 的内存分配请求可能耗尽 lower zones 的内存，但这样分配的内存未必是可释放的（freeable），亦或者/且最终不一定会被释放，这有可能导致 lower zones 的内存提前耗尽，而 higher zones 却仍保留有大量的内存。为了避免这样的一种情况的发生，lowmem_reserve 字段用以声明为该 zone 保留的内存，这一块内存别的 zone 是不能动的。

=node= ：这个字段只在 NUMA 系统中被启用，用以标识该 zone 所属的 node

=zone_pgdat= ：标识zone 所属的 pglist_data 节点

=zone_start_pfn= ：zone 的起始物理页帧编号

=spanned_pages= ： zone 对应的内存区域中的 pages 总数

=present_pages= ： zone 中存在的物理页框数

=managed_pages= ：zone 中 buddy system 管理的页面数量

=free_area= ：buddy system 按照 order 管理的页面，介绍伙伴算法的时候会再次讨论




**** page（页）

一个物理页，对应一个[page](https://elixir.bootlin.com/linux/v6.6/source/include/linux/mm_types.h#L74)结构体


在 page 结构体中专门有着一个匿名结构体用于存放与 slab 相关的成员

=flags= ：标志位

即该页的标志位成员，用以表示该页所处在的状态，每一个位表示一种状态，故一张页可以有 32 种不同的状态，这些状态定义于 [include/linux/page-flags.h](https://elixir.bootlin.com/linux/v6.6/source/include/linux/page-flags.h#L100) 中。






*** buddy system






** SLUB Internals

本篇文章这部分是学习内核堆利用时的视频笔记，视频源链接在最后。

*** 基本概念：

Slab分配器：是用来管理内核堆内存的基础设施
目前linux内核提供三种主流的实现：SLOB，SLAB，SLUB，这三种提供相同的接口供外部使用。其中SLUB是linux默认启用的，也可以在编译前通过修改编译配置文件，换成其他两种。

objects：slab可以分配出去小内存区域。

slabs：是保存objects的大内存区域，其上区域被切分成大小相同的内存区域称为object slots。这片内存是通过page_alloc分配的。

slot：是Slab分配器中预定义的 ​固定大小的内存块区间。

（slot和objects其实指代的东西相同，因为它们在内存上是重叠的，但是只是在不同场合他们的称呼不一样。区分不开问题也不大，理解工作流程即可。）

*** Slab bugs

典型的动态内存bugs：

- Out-of-bounds(OOB)越界读写

- Use-after-free(UAF)

- Double-free，invalid-free

攻击方式：

利用上述bug，可以达到overwrite和泄漏的目的。
因为free的object slot中存在元数据，我们可以通过覆盖链表的next指针，控制下一次的分配对象，获得任意地址读写，可以提权或者泄漏内核地址。堆上的内容也可能包含函数指针，我们可以控制它达成任意代码执行或者泄漏内核地址。具体的攻击措施还要看特定的漏洞详情。


*** 内核堆上的防护措施：

下一个free slot的指针被保存在free slot的中间附近，这样可以防止小范围的溢出破坏指针

#+BEGIN_SRC C
  
  cache->offset = ALIGN_DOWN(cache->object_size / 2, sizeof(void *));
  freeptr_addr = (unsigned long)object + cache->offset;

#+END_SRC

通过一个 ~CONFIG_SLAB_FREELIST_HARDENED=y~ 的编译配置选项，freelist指针会被加密保存。

#+BEGIN_SRC C

  cache->random = get_random_long();

  freelist_ptr = (void *)((unsigned long)ptr ^  cache->random ^ swab(ptr_addr));
  // ptr — actual value of freelist pointer
  // ptr_addr — location where freelist pointer is stored
  // swab() — exchanges adjacent even and odd bytes
  
#+END_SRC

ptr是freelist pointer的值，ptr_addr是freelist pointer被保存的地址，swab交换奇偶byte字节序。

所以要利用只能先泄漏 =cache->random= 和 =ptr_addr=，让利用更加困难。大多数现代 Slab 漏洞利用的是覆盖对象或者通过跨分配器攻击覆盖其他类型的内存。


通过 ~CONFIG_SLAB_FREELIST_RANDOM=y~ 配置，当分配新的 slab 时，SLUB 会打乱空闲列表中对象的顺序，这样让分配的地址更难预测。



*** slab关键数据结构

**** struct kmem_cache

#+BEGIN_SRC C

      struct kmem_cache {
          // Per-CPU cache data:
          struct kmem_cache_cpu __percpu *cpu_slab;
          // Per-node cache data:
          struct kmem_cache_node *node[MAX_NUMNODES];
          ...
          const char *name; // Cache name
          slab_flags_t flags; // Cache flags
          unsigned int object_size; // Size of objects
          unsigned int offset; // Freelist pointer offset
          unsigned long min_partial;
          unsigned int cpu_partial_slabs;
      };

#+END_SRC

比较关键的几个成员变量：

name: 内核有许多不同的caches，可以通过 =cat /proc/slabinfo= 查看其中name就是第一列的名字，该name通过kmem_cache_create的参数指定

object_size: 也是通过kmem_cache_create的参数指定，每一个cache只可以分配固定大小的内存。


cpu_slab:
SLUB分配器为每个CPU核心分配独立的kmem_cache_cpu结构，保存系统内特定cpu绑定的slab信息，目的是避免多核并发访问时的锁竞争。每个核心通过自己的kmem_cache_cpu直接从本地缓存分配内存对象。其内的slabs是绑定到特定CPU上的slab。在6.8版本以前也被称为froze  slabs，当CPU分配内存的时候，首先会从这些slabs中分配。

node：是为每个NUMA节点保存slab信息。NUMA的核心思想是把CPU分组，来简化资源的分配的复杂性。相当于拥有一个全局的slabs列表，尚未绑定到任何CPU，但是也仍然属于cache，也会包含已经分配的objects。

结构体详情：

#+BEGIN_SRC C

  struct kmem_cache_cpu {
      struct slab *slab;    // Active slab
      struct slab *partial; // Partial slabs
      ...
  };
  struct kmem_cache_node {
      struct list_head partial; // Slabs
      ...
  };
    
#+END_SRC


**** per-CPU

对于 =struct slab= 的简化信息：

#+BEGIN_SRC C
    struct slab {  // Aliased with struct page
        struct kmem_cache *slab_cache; // Cache this slab belongs to
        struct slab *next; // Next slab in per-cpu list
        int slabs; // Slabs left in per-cpu list
        struct list_head slab_list; // List links in per-node list
        void *freelist; // Per-slab freelist
        ...
  };
  
#+END_SRC

slab是一个 struct slab 的结构体，上述是简化的版本，struct slab 别名为struct page，提到这就不得不提一下历史了，在Linux内核5.17版本中，struct slab被引入，目的是将slab相关的字段从struct page中分离出来。struct page（每一个物理页面都有一个相应的page对应）之前包含了很多不同用途的字段，使用union来适应不同场景，导致结构复杂。现在struct slab作为struct page的一个overlay，共享同一块内存，但隐藏了struct page的细节，这样slab分配器只需要处理自己的结构。

slab_cache指向自己属于的cache。

每一个slab都有后备内存，后备内存是通过page_alloc想buddy system分配。不需要指针指向它，struct slab本身就是一个struct page

包含object slots，[size](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L4137)是基于objects大小计算出来的。

freelist指针指向第一个slab中free的slot，下一个free slot的指针被保存在free slot中。freelist最后一个指针是NULL，objects都是从链表头分配，free也是插入链表头。

full slabs是指没有free slot的slab，此时它的freelist 指针是NULL。

多个slab可以用链表结构串联在一起。per-CPU的是单链表， =struct slab= 中的 =next= 指针，per-node的是双链表， =struct slab= 中的 =list_head slab_list= 。


**** active slab

先来看下kmem_cache_cpu的active slab，per-CPU的slabs的其中之一被设计成激活的，并把slab成员指针赋值为该slab。分配object的时候会首先从这个slab中分配。

active slab有两个freelists。 =kmem_cache_cpu->freelist= 和 =kmem_cache_cpu->slab->freelist= 都指向它的slots。但是两个链表并不相交，
=kmem_cache_cpu->freelist= 用来给绑定的CPU分配释放内存的。

=kmem_cache_cpu->slab->freelist= 被用来给其他CPUs分配释放内存的（这个模块的代码有可能不只在一个cpu上运行，可能会在任务切换过程中跑到其他cpu上执行了）。


**** partial slabs

partial意思是这些slab有空闲slot（至少有一个，也有可能是fully free）。

每个partial slabs都有后备内存。

只有一个freelist，

只在active slab变为full后被使用。

per-CPU partial slabs的列表最大数量是有限的，这个大小是由kmem_cache->cpu_partial_slabs字段指定，这个值是根据object和slab的大小计算出来的[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L4364) 用户空间是无法查看这个字段值的，只能查看 =/sys/kernel/slab/$CACHE/cpu_partial= ，然后自己计算出cpu_partial_slabs。


**** per-node 

kmem_cache_node 有一个per-node partial slabs的列表。这就意味这每一个都至少有一个free slots。

每一个都有后备内存和一个freelist。

一旦per-CPU中的slabs都用完都变成full后他们就会被使用。

per-node slabs 的最小数量也是有限制的。由kmem_cache->min_partial指定， 计算也是基于object的大小[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L4543)

可以在用户空间中查看 =/sys/kernel/slab/$CACHE/min_partial= 




**** full slabs

full slabs 不会被tracked。没有指针指向full slabs（除非开启slub_debug），一旦任意一个object被释放到full slab中，分配器会获得指向该slab的指针。我们只需使用[virt_to_slab](https://elixir.bootlin.com/linux/v6.6/source/mm/slab.h#L211)计算。





*** 分配过程

为了方便介绍，这里分为五个不同层次的分配过程

**** 1. allocating from lockless per-CPU freelist kmem_cache_cpu->freelist

当无锁的该cpu slab的freelist是不为空，那么就会分配该freelist的第一个object

如果为空，goto 2。


**** 2. allocating from active slab (kmem_cache_cpu->slab->freelist)

如果active slab freelist不是空的，

首先move active slab freelist到 lockless per-CPU freelist；[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3151)

然后从这个lockless的per-CPU freelist分配第一个object。[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3176)并更新这个freelist[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3173)

如果这个active slab freelist为空。 goto 3[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3158)



**** 3. allocating from per-CPU partial slabs (kmem_cache_cpu->partial)

如果有per-CPU的partial slabs：

首先将链表中的第一个脱链，并指定为active slabs [link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3206)

goto 2[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3210)

如果per-CPU的partial slabs是空的

goto 4[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3213)



**** 4. allocating from per-node partial slabs (kmem_cache_node->partial)

如果有per-node的partial slabs：
首先将链表中的第一个脱链，并指定为active slabs[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2309)；然后移动一些(最多cpu_partial_slabs / 2[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2319))per-node的slabs到per-CPU的partial list[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2313)；再去active slab重新分配。[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3220)

如果per-node partial list 为空，goto 5




**** 5. Create new slab

[allocate](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3223) from new slab的过程：

首先从page_alloc中分配新的slab，并放进freelist中，并指定为active slab，然后从该slab中分配对象。





*** explotion case

1. Out-of-bounds, case #1 (Shaping Slab memory)

   攻击所需条件：

   1) 需要一个内核bug能导致OOB；
   2) 有两个不同的系统调用，一个可以分配object(IOCTL_ALLOC)，一个可以OOB(IOCTL_OOB)；
   3) 能够leak或者overwrite的目标object；
   4) 能将可利用的object和targetobject挨着放在一起。

   攻击过程：
   1) allocate 足够的targt objects 来获取新的active slab；需要填充所有的holes达到分配过程的第五步。

      所以我们就需要找到有多少个holes。
      但是在非特权的目标系统上，没有方法能够找到确切的数目。 =/proc/slabinfo= 和相关文件对于普通用户不可读。

      而且我们可能拥有的空闲插槽数量没有上限，原因是atcive slab上的holes数量最多有每一个slab上的objects的数目。
      per-CPU partials的holes数量上限是每一个slab上的objects的数目 x cpu_partial_slabs。
      per-node partials的没有限制slabs的数量。

      
      所以一种方式是估计，首先重现目标环境，运行相同的版本内核，运行相同的软件，然后我们通过 =cat /proc/slabinfo= 看有多少个holes。

      还有一种[基于时间信道](https://stefangast.eu/papers/slubstick.pdf)的方式。


      | name       | <active_objs> | <num_objs> | <objsize> | <objperslab> | <pagesperslab> |
      |------------+---------------+------------+-----------+--------------+----------------|
      | cred_jar   |          7644 |       7644 |       192 |           21 |              1 |
      | kmalloc-8k |           456 |        460 |      8192 |            4 |              8 |
      | kmalloc-4k |          3118 |       3160 |      4096 |            8 |              8 |
      | kmalloc-2k |          3621 |       3696 |      2048 |           16 |              8 |
      | kmalloc-32 |         54789 |      55808 |        32 |          128 |              1 |


      active_objs: 已经分配的objects的数量，
      num_objs: 现存slab中的slots的总数。
      这个值不是实时更新的，只有在一个slab被分配，释放或者移动到per-node partial list时才会更新。

      Shrink cache 可以获得更准确的值，

      =echo 1 | sudo tee /sys/kernel/slab/kmalloc-32/shrink=

      但是这样会导致这个cache释放fully free slabs。

      | # name     | <active_objs> | <num_objs>                     |
      |------------+---------------+--------------------------------|
      | kmalloc-32 |         25216 | 25216     // Before shrinking. |
      | kmalloc-32 |         23132 | 24320     // After shrinking.  |

      比如这个就少了1000多个，这个就是不准确的，即是我们复制来环境也不准确。

  2) 现在假设我们分配了足够的target objects并获得了一个新的active slab。并且新的active slab被target objects填充一部分；

  3) 现在通过IOCTL_ALLOC操作分配一个vulnerable object；
     现在分配足够的target objects填满active slab。现在slab变成full，尽管可能会变成非active，但是没关系。

     现在内存看起来是这样：

     #+BEGIN_SRC C
       +-------+-------+-------+-------+-------+-------+-------+-------+
       | Target| Target| Target| Vuln  | Target| Target| Target| Target|
       +-------+-------+-------+-------+-------+-------+-------+-------+

     #+END_SRC
     
  4) 现在通过IOCTL_OOB触发越界访问。
      

       #+BEGIN_SRC C
         +-------+-------+-------+-------+-------+-------+-------+-------+
         | Target| Target| Target| Vuln  | Target| Target| Target| Target|
         +-------+-------+-------+-------+-------+-------+-------+-------+
                                     |_______| OOB
       #+END_SRC


       （注：如果没有第一步，我们就无法破坏target，并且可能会破坏内核其他数据，后果不可控。所以第一步是为了explition的稳定。
       除此之外这个exp也有一些问题，比如:
       如果vuln被allocated到最后一个object，这就有概率会失败。解决的办法就是在其后多分配一个slab，然后填充target。
       Migration: 进程被移动到另一个CPU上执行了。解决办法：绑定CPU的亲和性
       Preempting: 另一个进程或者中断处理来抢占此CPU，解决方法：减少slab shaping的时间；使用less noisy（不那么频繁） 的cache。）

2. Out-of-bounds, case #2 （Shaping Slab memory）

   需要条件：分配vulnerable objects并且立即写数据触发OOB（IOCTL_ALLOC_AND_OOB），

   攻击过程：
   1) 分配足够多的target objects以获得新的 active slab；

   2) 分配一个vulnerable object并且触发OOB通过IOCTL_ALLOC_AND_OOB，

      这有两种情况，
      case #1: OOB访问的区域在free slot中，如果OOB的范围很小，没有覆盖元数据，则不会发生任何事情。可以重复进行OOB操作。
       #+BEGIN_SRC C
         +-------+-------+-------+-------+-------+-------+-------+-------+
         | Target|       | Target| Vuln  |       | Target| Target| Target|
         +-------+-------+-------+-------+-------+-------+-------+-------+
                                     |_______| OOB
       #+END_SRC


      case #2: OOB访问的区域在target object中

      Success！！！ 但是也许需要很多次重试才能成功
          
       #+BEGIN_SRC C
         +-------+-------+-------+-------+-------+-------+-------+-------+
         | Target|       | Target| Vuln  | Target| Target| Target| Target|
         +-------+-------+-------+-------+-------+-------+-------+-------+
                                     |_______| OOB
       #+END_SRC


*** Freeing process and explition

1. case #1: object 属于active slab，

   object加入无锁的per-CPU的freelist的头部。[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3766)

   想象一种场景:

   #+BEGIN_SRC C
     void *ptr1 = kmalloc(128, GFP_KERNEL);
     free(ptr1);
     void *ptr2 = kmalloc(128, GFP_KERNEL);
     free(ptr2);
     void *ptr3 = kmalloc(128, GFP_KERNEL);
     
   #+END_SRC
   ptr1，ptr2，ptr3都指向同一个object。

   所以这就引出第一种利用场景(UAF)

   所需条件：假设我们有UAF的漏洞：
   1) 分配vulnerable object （IOCTL_ALLOC）

   2) free vulnerable object （IOCTL_FREE）

   3) 在IOCTL_FREE后，读写vulnerable object的数据，（IOCTL_UAF）

   攻击过程：
   1) 通过IOCTL_ALLOC分配一个vulnerable object，

   2) 通过IOCTL_FREE free vulnerable object，悬空引用仍然存在；

   3) 分配一个target object，现在那个悬空指针指向它；

   4) 现在能够使用IOCTL_UAF触发UAF访问。

2. case #2: object属于一个non-full slab

   free object到所属的freelist之中。[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3661)

   如果slab是per-node的，并且变成了fully free，并且node有足够的per-node slabs。该slab会被从per-node中移除并[free](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3687)回page allocator中。

   如果object属于non-full non-current-active slab：[free](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3661)object 到slab freelist中可能会[free] (https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3687)per-node的full slab，但是[不适用于](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3666)per-CPU partial或者active slabs（即使变成full free也不会free回page_alloca，仍然待在相应列表中） 

   如果object属于另一个CPU的active slab，将会把它放到active slab的freelist（不是per-CPU的freelist）中[link](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3661)。

   

3. case #3: object 属于full slab

   [free](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3661) object 到slab fresslist

   [move](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3679) slab到per-CPU的partial list：

   如果per-CPU的partial list[没满](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2716)（<cpu_partial_slabs），就把它放到链表头中。

   如果per-CPU的partial list已经[满了](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2708)（>=cpu_partial_slabs），free_up per-CPU partial list遍历链表并执行执行以下操作

     [Move](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2642) per-CPU slabs 到per-node list的尾部，

     [free](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2655) full freed per-CPU slabs 到page_alloc中（可用于cross-cache的攻击）

     直到per-node 的slabs的数量达到min_partial

     现在per-CPU的partial list有空间了，将该slab[放进](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L2726)链表头中




*** explition case


1. OOB变UAF

  所需条件：1)分配vulnerable object（IOCTL_ALLOC）

  2)可以越界向vulnerable object写数据。


  攻击流程：slab已经经过我们的shaping成full slab，并且有一个OOB的vuln object。如果我们现在有一个Vuln的object可以OOB，我们把它在内存上挨着的下一个object视为target object，target object有引用计数之类的东西，通过溢出后就可以控制引用计数，原来的程序会在错误的时机free target object然后我们就可以将target object变成一个UAF。并且该slab会被添加到per-CPU的partial list的头部
  
  （注：在shaping slab的时候，我们可以用slab spraying的方式：分配很多的objects，所以问题就是我们需要spray多少个object，这个数量需要根据实际情况来看。）

2. allocation和OOB组合在一起

   所需条件：1) allocate vulnerable object并且立即写入OOB数据（IOCTL_ALLOC_AND_OOB）

   攻击流程：

   1) 分配足够的target objects能获取新的active slab，

   2) 分配更多的target objects去填充这个slab，直到slab变成full，

   3) 从这个slab中free一个target object，

   4) 现在我们重新使用这个free slot，并且使用IOCTL_ALLOC_AND_OOB去溢出内存中挨着的下一个targe object。


3. double-free

   ~CONFIG_SLAB_FREELIST_HARDENED=y~ 开启这个编译选项后，double-free会被[检测](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L448)到
  

*** 总结

slub机制是十分复杂的，并且其中还有很多的情况和优化需要考虑，本文只是浅浅涉猎一下。

[SLUB source](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c)

[__slab_alloc_node](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3329)allocation 过程开始的地方

[do_slab_free](https://elixir.bootlin.com/linux/v6.6/source/mm/slub.c#L3734)free 过程开始的地方


*** 拓展阅读

[Freeing free slot via double-free can be used for cross-cache attacks](https://arxiv.org/pdf/2406.02624)

More details about how SLUB works:[Linux SLUB Allocator Internals and Debugging](https://blogs.oracle.com/linux/post/linux-slub-allocator-internals-and-debugging-1)[note](https://lore.kernel.org/linux-mm/c71a884d-714f-4741-906f-4df162bde303@suse.cz/)

About cache merging, accounting, and hardened usercopy:[Linux kernel heap feng shui in 2022](https://duasynt.com/blog/linux-kernel-heap-feng-shui-2022)

Introduction to cross-cache use-after-free attacks:[CVE-2022-29582, An io_uring vulnerability](https://ruia-ruia.github.io/2022/08/05/CVE-2022-29582-io-uring/)


Improving reliability of Slab shaping:

[Playing for K(H)eaps: Understanding and Improving Linux Kernel Exploit Reliability](https://haehyun.github.io/papers/playing-for-keaps-22-sec.pdf)

[PSPRAY: Timing Side-Channel based
Linux Kernel Heap Exploitation Technique](https://www.usenix.org/system/files/sec23summer_79-lee-prepub.pdf)

[SLUBStick: Arbitrary Memory Writes through
Practical Software Cross-Cache Attacks within the Linux Kernel](https://stefangast.eu/papers/slubstick.pdf)


*** 参考链接

[SLUB演讲视频连接](https://www.youtube.com/watch?v=XulsBDV4n3w)

[PPT](https://static.sched.com/hosted_files/lsseu2024/37/2024,%20LSS%20EU_%20SLUB%20Internals%20for%20Exploit%20Developers.pdf)
